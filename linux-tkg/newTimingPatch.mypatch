diff --git a/arch/x86/kvm/svm/svm.c b/arch/x86/kvm/svm/svm.c
index 309725151313..beb5cf93e4be 100644
--- a/arch/x86/kvm/svm/svm.c
+++ b/arch/x86/kvm/svm/svm.c
@@ -1168,6 +1168,7 @@ static void init_vmcb(struct vcpu_svm *svm)
 	svm_set_intercept(svm, INTERCEPT_XSETBV);
 	svm_set_intercept(svm, INTERCEPT_RDPRU);
 	svm_set_intercept(svm, INTERCEPT_RSM);
+	svm_set_intercept(svm, INTERCEPT_RDTSC);
 
 	if (!kvm_mwait_in_guest(svm->vcpu.kvm)) {
 		svm_set_intercept(svm, INTERCEPT_MONITOR);
@@ -2350,6 +2351,8 @@ static int skinit_interception(struct vcpu_svm *svm)
 
 static int wbinvd_interception(struct vcpu_svm *svm)
 {
+	svm->vcpu.run->exit_reason = 123;
+	
 	return kvm_emulate_wbinvd(&svm->vcpu);
 }
 
@@ -2358,6 +2361,8 @@ static int xsetbv_interception(struct vcpu_svm *svm)
 	u64 new_bv = kvm_read_edx_eax(&svm->vcpu);
 	u32 index = kvm_rcx_read(&svm->vcpu);
 
+	svm->vcpu.run->exit_reason = 123;
+	
 	int err = kvm_set_xcr(&svm->vcpu, index, new_bv);
 	return kvm_complete_insn_gp(&svm->vcpu, err);
 }
@@ -2434,6 +2439,7 @@ static int task_switch_interception(struct vcpu_svm *svm)
 
 static int cpuid_interception(struct vcpu_svm *svm)
 {
+	svm->vcpu.run->exit_reason = 123;
 	return kvm_emulate_cpuid(&svm->vcpu);
 }
 
@@ -2451,6 +2457,8 @@ static int iret_interception(struct vcpu_svm *svm)
 
 static int invd_interception(struct vcpu_svm *svm)
 {
+	svm->vcpu.run->exit_reason = 123;
+	
 	/* Treat an INVD instruction as a NOP and just skip it. */
 	return kvm_skip_emulated_instruction(&svm->vcpu);
 }
@@ -3104,6 +3112,24 @@ static int invpcid_interception(struct vcpu_svm *svm)
 	return kvm_handle_invpcid(vcpu, type, gva);
 }
 
+static int handle_rdtsc_interception(struct vcpu_svm *svm) 
+{
+	u64 differece;
+	u64 final_time;
+	u64 data;
+	
+	differece = rdtsc() - svm->vcpu.last_exit_start;
+	final_time = svm->vcpu.total_exit_time + differece;
+
+	data = rdtsc() - final_time;
+
+	svm->vcpu.arch.regs[VCPU_REGS_RAX] = data & -1u;
+	svm->vcpu.arch.regs[VCPU_REGS_RDX] = (data >> 32) & -1u;
+
+	svm->vcpu.run->exit_reason = 123;
+	return nop_interception(svm);
+}
+
 static int (*const svm_exit_handlers[])(struct vcpu_svm *svm) = {
 	[SVM_EXIT_READ_CR0]			= cr_interception,
 	[SVM_EXIT_READ_CR3]			= cr_interception,
@@ -3175,6 +3201,7 @@ static int (*const svm_exit_handlers[])(struct vcpu_svm *svm) = {
 	[SVM_EXIT_RSM]                          = rsm_interception,
 	[SVM_EXIT_AVIC_INCOMPLETE_IPI]		= avic_incomplete_ipi_interception,
 	[SVM_EXIT_AVIC_UNACCELERATED_ACCESS]	= avic_unaccelerated_access_interception,
+	[SVM_EXIT_RDTSC]                = handle_rdtsc_interception,
 	[SVM_EXIT_VMGEXIT]			= sev_handle_vmgexit,
 };
 
diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c
index 3406ff421c1a..85bdc0771952 100644
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@ -3355,6 +3355,9 @@ static int get_msr_mce(struct kvm_vcpu *vcpu, u32 msr, u64 *pdata, bool host)
 
 int kvm_get_msr_common(struct kvm_vcpu *vcpu, struct msr_data *msr_info)
 {
+	u64 differece;
+	u64 final_time;
+	
 	switch (msr_info->index) {
 	case MSR_IA32_PLATFORM_ID:
 	case MSR_IA32_EBL_CR_POWERON:
@@ -3423,10 +3426,12 @@ int kvm_get_msr_common(struct kvm_vcpu *vcpu, struct msr_data *msr_info)
 		 * return L1's TSC value to ensure backwards-compatible
 		 * behavior for migration.
 		 */
-		u64 tsc_offset = msr_info->host_initiated ? vcpu->arch.l1_tsc_offset :
-							    vcpu->arch.tsc_offset;
+		differece = rdtsc() - vcpu->last_exit_start;
+		final_time = vcpu->total_exit_time + differece;
 
-		msr_info->data = kvm_scale_tsc(vcpu, rdtsc()) + tsc_offset;
+		msr_info->data = rdtsc() - final_time;
+
+		vcpu->run->exit_reason = 123;
 		break;
 	}
 	case MSR_MTRRcap:
@@ -8920,7 +8925,7 @@ EXPORT_SYMBOL_GPL(__kvm_request_immediate_exit);
  * exiting to the userspace.  Otherwise, the value will be returned to the
  * userspace.
  */
-static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
+static int vcpu_enter_guest_real(struct kvm_vcpu *vcpu)
 {
 	int r;
 	bool req_int_win =
@@ -9244,6 +9249,24 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 	return r;
 }
 
+static int vcpu_enter_guest(struct kvm_vcpu *vcpu) 
+{
+	int result;
+	u64 differece;
+
+	vcpu->last_exit_start = rdtsc();
+
+	result = vcpu_enter_guest_real(vcpu);
+
+	if (vcpu->run->exit_reason == 123) 
+	{
+		differece = rdtsc() - vcpu->last_exit_start;
+		vcpu->total_exit_time += differece;
+	}
+
+	return result;
+}
+
 static inline int vcpu_block(struct kvm *kvm, struct kvm_vcpu *vcpu)
 {
 	if (!kvm_arch_vcpu_runnable(vcpu) &&
diff --git a/include/linux/kvm_host.h b/include/linux/kvm_host.h
index 99dccea4293c..c062d7e51ca8 100644
--- a/include/linux/kvm_host.h
+++ b/include/linux/kvm_host.h
@@ -288,6 +288,9 @@ struct kvm_vcpu {
 	unsigned int halt_poll_ns;
 	bool valid_wakeup;
 
+	u64 last_exit_start;
+	u64 total_exit_time;
+
 #ifdef CONFIG_HAS_IOMEM
 	int mmio_needed;
 	int mmio_read_completed;
